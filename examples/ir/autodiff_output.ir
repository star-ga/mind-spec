# MIND Core IR Example: Autodiff-Generated Gradient Module
# Specification reference: spec/v1.0/autodiff.md
# Grammar reference: spec/v1.0/grammar-ir.ebnf
#
# This shows the gradient IR generated by autodiff for:
#   f(x, y) = sum((x * y) + x)
#
# Forward pass produces the loss.
# Backward pass computes gradients.

# ============================================
# FORWARD PASS (primal computation)
# ============================================

# Inputs with gradient tracking
%0 = Input() {name: "x"} : Tensor<f32, [2, 3]>
%1 = Input() {name: "y"} : Tensor<f32, [2, 3]>

# x * y (elementwise)
%2 = BinOp(Mul, %0, %1) : Tensor<f32, [2, 3]>

# (x * y) + x
%3 = BinOp(Add, %0, %2) : Tensor<f32, [2, 3]>

# sum((x * y) + x) -> scalar loss
%4 = Sum(%3, [], false) : Tensor<f32, []>

# ============================================
# BACKWARD PASS (gradient computation)
# Reference: spec/v1.0/autodiff.md
# ============================================

# Seed gradient (dloss/dloss = 1)
%5 = ConstF32(1.0) : Tensor<f32, []>

# Backward through Sum: broadcast gradient to input shape
# Reference: spec/v1.0/autodiff.md#reduction-gradients
# d(Sum)/d(input) = ones(input.shape) * grad_output
%6 = ConstTensor([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]]) : Tensor<f32, [2, 3]>
%7 = BinOp(Mul, %5, %6) : Tensor<f32, [2, 3]>

# Backward through Add: gradient flows to both operands
# Reference: spec/v1.0/autodiff.md#binary-operation-gradients
# d(a + b)/da = grad_output
# d(a + b)/db = grad_output
%8 = %7  # grad for left operand (x) from add
%9 = %7  # grad for right operand (x*y) from add

# Backward through Mul: product rule
# Reference: spec/v1.0/autodiff.md#binary-operation-gradients
# d(x * y)/dx = y * grad_output
# d(x * y)/dy = x * grad_output
%10 = BinOp(Mul, %1, %9) : Tensor<f32, [2, 3]>  # dx from mul
%11 = BinOp(Mul, %0, %9) : Tensor<f32, [2, 3]>  # dy from mul

# Accumulate gradients for x (appears twice in forward)
# grad_x = grad_from_add + grad_from_mul
%12 = BinOp(Add, %8, %10) : Tensor<f32, [2, 3]>

# Final gradients
# grad_x = y + 1 (from df/dx = y + 1)
# grad_y = x     (from df/dy = x)

# Output: loss and gradients
outputs: %4, %12, %11
# Interpretation: (loss, grad_x, grad_y)
